{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "laden-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib\n",
    "\n",
    "pwd = !pwd\n",
    "ROOT = Path(pwd[0])\n",
    "\n",
    "def vid_to_path(vid: str):\n",
    "    path = ROOT / \"data\" / vid[:1] / vid\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)\n",
    "    return path\n",
    "\n",
    "\n",
    "def yts_to_vid(yts: str):\n",
    "    url_data = urllib.parse.urlparse(yts)\n",
    "    query = urllib.parse.parse_qs(url_data.query)\n",
    "    vid = query[\"v\"][0]\n",
    "    return vid\n",
    "\n",
    "\n",
    "def yts_to_path(yts: str):\n",
    "    vid = yts_to_vid(yts)\n",
    "    return vid_to_path(vid)\n",
    "\n",
    "\n",
    "def vid_to_yts(vid: str):\n",
    "    return f\"https://www.youtube.com/watch?v={vid}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "intimate-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "targets = pd.DataFrame([{\n",
    "    'vid': x.parent.name,\n",
    "    'target': (x.parent / \"score.txt\").read_text()\n",
    "}\n",
    "    for x in ROOT.rglob('thumb.jpg')\n",
    "])\n",
    "targets.to_csv('targets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-exposure",
   "metadata": {},
   "source": [
    "Sample Solution\n",
    "\n",
    " 1. Apply a mask to the thumbnail around Melonhead himself\n",
    " 2. Extract relevant features from pixels within the mask\n",
    " 3. Train classifier, profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wanted-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "targets = pd.read_csv(\"targets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "upset-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(ROOT.rglob('thumb.jpg'))), len()\n",
    "\n",
    "_scores = list(map(lambda x: x.parent, list(ROOT.rglob('thumb.jpg'))))\n",
    "for f in list(ROOT.rglob('score.txt')):\n",
    "    if f.parent not in _scores:\n",
    "        shutil.rmtree(f.parent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vanilla-pressing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "MASKING_SHAPE = (188, 336, 3)\n",
    "\n",
    "left = lambda pt: 3.13333 * pt[1] - 470 < -pt[0]\n",
    "right = lambda pt: 564 - 2.35 * pt[1] < -pt[0]\n",
    "horiz = lambda pt: -90 < -pt[0] \n",
    "\n",
    "\n",
    "def get_mask(shape):\n",
    "    arr = np.full(shape, False)\n",
    "    for x in range(shape[1]):\n",
    "        for y in range(shape[0]):\n",
    "            arr[y, x] = not left((y, x)) and not right((y, x)) and not horiz((y, x))\n",
    "            \n",
    "    return arr\n",
    "\n",
    "MASK = get_mask(MASKING_SHAPE[:2])\n",
    "MASK = np.asarray([MASK, MASK, MASK]).transpose((1, 2, 0))\n",
    "plt.imshow(MASK[:,:,0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impressed-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2492/2492 [01:24<00:00, 29.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import binascii\n",
    "import struct\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_CLUSTERS = 5\n",
    "\n",
    "def get_colour(r, g, b):\n",
    "    \"\"\"Find a colour that is indicative of the dominant colour\"\"\"\n",
    "    ar = np.asarray([np.stack((r, g, b), axis=-1)])\n",
    "    shape = ar.shape\n",
    "    ar = ar.reshape(np.product(shape[:2]), shape[2]).astype(float)\n",
    "    codes, dist = scipy.cluster.vq.kmeans(ar, NUM_CLUSTERS)\n",
    "    vecs, dist = scipy.cluster.vq.vq(ar, codes)         # assign codes\n",
    "    counts, bins = np.histogram(vecs, len(codes))    # count occurrences\n",
    "    index_max = np.argmax(counts)                    # find most frequent\n",
    "    peak = codes[index_max]\n",
    "    r, g, b = peak\n",
    "    colour = binascii.hexlify(bytearray(int(c) for c in peak)).decode('ascii')\n",
    "    return colour, r, g, b\n",
    "\n",
    "\n",
    "def load_example(path, mask, dsfact: int = 1):\n",
    "    thumb_path = path / \"thumb.jpg\"\n",
    "    img = Image.open(thumb_path)\n",
    "    if np.array(img).shape != MASK.shape:\n",
    "        img = img.resize((MASK.shape[1], MASK.shape[0]), Image.ANTIALIAS)\n",
    "    ds_mask = mask[::dsfact, ::dsfact, :]\n",
    "    ds_img  = np.array(img)[::dsfact, ::dsfact, :]\n",
    "    features = ds_img[ds_mask]\n",
    "    r, g, b = ds_img[..., 0][ds_mask[..., 0]], ds_img[..., 1][ds_mask[..., 0]], ds_img[..., 2][ds_mask[..., 0]]\n",
    "    return np.array(img), features, path.name, (r, g, b)\n",
    "\n",
    "\n",
    "paths = list(map(vid_to_path, targets.vid))\n",
    "\n",
    "\n",
    "vids = []\n",
    "scores = []\n",
    "features = []\n",
    "rgbs = []\n",
    "colours = []\n",
    "for p in tqdm(paths):\n",
    "    img, img_features, vid, rgb = load_example(p, MASK, 3)\n",
    "    vids.append(vid)\n",
    "    features.append(img_features)\n",
    "    colour, r, g, b = get_colour(*rgb)\n",
    "    rgbs.append([*rgb])\n",
    "    colours.append(colour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "presidential-malawi",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2492it [00:09, 252.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "rgb_features = []\n",
    "for rgb, colour in tqdm(zip(rgbs, colours)):\n",
    "    rgb_features.append(\n",
    "        pd.Series(rgb[0]).describe().tolist()\n",
    "        + pd.Series(rgb[1]).describe().tolist()\n",
    "        + pd.Series(rgb[2]).describe().tolist()\n",
    "        + list(map(lambda x: int(x, 16), [colour[0:2], colour[2:4], colour[4:6]]))\n",
    "    )\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(rgb_features)\n",
    "rgb_features = scaler.transform(rgb_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "owned-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1        7\n",
       "2        6\n",
       "3        8\n",
       "4        4\n",
       "        ..\n",
       "2487     6\n",
       "2488    10\n",
       "2489     8\n",
       "2490     0\n",
       "2491     8\n",
       "Name: target, Length: 2492, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_val = targets['target'].apply(lambda x: int(x) if x.isnumeric() else (10 if x == \"CLASSIC\" else 0))\n",
    "target_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "postal-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6914893617021276"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.asarray(rgb_features), \n",
    "    target_val, \n",
    "    test_size=0.33, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regr = RandomForestRegressor(random_state=0, verbose=True, n_jobs=8)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "y_test_int = pd.Series(y_test).apply(int)\n",
    "y_pred_int = pd.Series(y_pred).apply(int)\n",
    "\n",
    "average_error = np.mean(np.abs(y_test_int - y_pred_int))\n",
    "average_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outstanding-bernard",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12,  1,  0,  1,  1,  2,  3,  8,  1,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  1,  1,  0,  1,  4,  2,  0,  0],\n",
       "       [ 0,  0,  0,  3,  2,  1,  8,  3,  8,  0,  0],\n",
       "       [ 1,  0,  0,  2,  9,  3,  9, 24, 14,  0,  0],\n",
       "       [ 1,  0,  0,  2,  3, 11, 39, 51, 24,  0,  0],\n",
       "       [ 2,  0,  0,  0,  4, 18, 42, 65, 25,  1,  0],\n",
       "       [ 1,  0,  0,  1,  0, 21, 43, 83, 30,  1,  2],\n",
       "       [ 1,  0,  0,  1,  2, 13, 44, 57, 65,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  3,  2, 22,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  2,  5,  4,  4,  0,  0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "regr = RandomForestClassifier(random_state=0, verbose=True, n_jobs=8, class_weight='balanced')\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "cm(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-silver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
